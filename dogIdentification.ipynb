{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import PIL\n",
    "import glob, os\n",
    "import time\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "DESIRED_WIDTH = 128\n",
    "DESIRED_HEIGHT = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records have been processed\n",
      "100 records have been processed\n",
      "200 records have been processed\n",
      "300 records have been processed\n",
      "400 records have been processed\n",
      "500 records have been processed\n",
      "600 records have been processed\n",
      "700 records have been processed\n",
      "800 records have been processed\n",
      "900 records have been processed\n",
      "1000 records have been processed\n",
      "1100 records have been processed\n",
      "1200 records have been processed\n",
      "1300 records have been processed\n",
      "1400 records have been processed\n",
      "1500 records have been processed\n",
      "1600 records have been processed\n",
      "1700 records have been processed\n",
      "1800 records have been processed\n",
      "1900 records have been processed\n",
      "2000 records have been processed\n",
      "2100 records have been processed\n",
      "2200 records have been processed\n",
      "2300 records have been processed\n",
      "2400 records have been processed\n",
      "2500 records have been processed\n",
      "2600 records have been processed\n",
      "2700 records have been processed\n",
      "2800 records have been processed\n",
      "2900 records have been processed\n",
      "3000 records have been processed\n",
      "3100 records have been processed\n",
      "3200 records have been processed\n",
      "3300 records have been processed\n",
      "3400 records have been processed\n",
      "3500 records have been processed\n",
      "3600 records have been processed\n",
      "3700 records have been processed\n",
      "3800 records have been processed\n",
      "3900 records have been processed\n",
      "4000 records have been processed\n",
      "4100 records have been processed\n",
      "4200 records have been processed\n",
      "4300 records have been processed\n",
      "4400 records have been processed\n",
      "4500 records have been processed\n",
      "4600 records have been processed\n",
      "4700 records have been processed\n",
      "4800 records have been processed\n",
      "4900 records have been processed\n",
      "5000 records have been processed\n",
      "5100 records have been processed\n",
      "5200 records have been processed\n",
      "5300 records have been processed\n",
      "5400 records have been processed\n",
      "5500 records have been processed\n",
      "5600 records have been processed\n",
      "5700 records have been processed\n",
      "5800 records have been processed\n",
      "5900 records have been processed\n",
      "6000 records have been processed\n",
      "6100 records have been processed\n",
      "6200 records have been processed\n",
      "6300 records have been processed\n",
      "6400 records have been processed\n",
      "6500 records have been processed\n",
      "6600 records have been processed\n",
      "6700 records have been processed\n",
      "6800 records have been processed\n",
      "6900 records have been processed\n",
      "7000 records have been processed\n",
      "7100 records have been processed\n",
      "7200 records have been processed\n",
      "7300 records have been processed\n",
      "7400 records have been processed\n",
      "7500 records have been processed\n",
      "7600 records have been processed\n",
      "7700 records have been processed\n",
      "7800 records have been processed\n",
      "7900 records have been processed\n",
      "8000 records have been processed\n",
      "8100 records have been processed\n",
      "8200 records have been processed\n",
      "8300 records have been processed\n",
      "8400 records have been processed\n",
      "8500 records have been processed\n",
      "8600 records have been processed\n",
      "8700 records have been processed\n",
      "8800 records have been processed\n",
      "8900 records have been processed\n",
      "9000 records have been processed\n",
      "9100 records have been processed\n",
      "9200 records have been processed\n",
      "9300 records have been processed\n",
      "9400 records have been processed\n",
      "9500 records have been processed\n",
      "9600 records have been processed\n",
      "9700 records have been processed\n",
      "9800 records have been processed\n",
      "9900 records have been processed\n",
      "10000 records have been processed\n",
      "10100 records have been processed\n",
      "10200 records have been processed\n",
      "1933.1214890480042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flag = 0\n",
    "\n",
    "count=-1\n",
    "labelsLocation = \"C://Users//Kevin//Workspaces//Data//dogIdentification//labels.csv\"\n",
    "fileImagesLocation = \"C://Users//Kevin//Workspaces//Data//train\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "os.chdir(fileImagesLocation)\n",
    "\n",
    "train_y = []    \n",
    "labels=pd.read_csv(labelsLocation, sep=',')\n",
    "\n",
    "#Building train_x\n",
    "for file in glob.glob(\"*.jpg\"):\n",
    "    count += 1\n",
    "    \n",
    "    original_image = PIL.Image.open(file)\n",
    "    transformed_image = original_image.resize( (DESIRED_HEIGHT, DESIRED_WIDTH) )\n",
    "    tempArray = numpy.array(transformed_image)\n",
    "    tempArray = numpy.expand_dims(tempArray, axis = 0)\n",
    "\n",
    "    if flag == 0:\n",
    "        train_x = tempArray\n",
    "        flag = 1\n",
    "    else:\n",
    "        train_x = numpy.append(train_x, tempArray, axis=0)\n",
    "        \n",
    "\n",
    "    #building train_y part 1\n",
    "    for x in range(labels.shape[0]):\n",
    "        tempFlag = 0\n",
    "        if labels.iloc[x,0] == file[:-4]:\n",
    "            train_y.append(labels.iloc[x,1])\n",
    "            labels.drop([x])\n",
    "            tempFlag = 1\n",
    "            break\n",
    "    if tempFlag == 0:\n",
    "        train_y.append(\"unknown\")\n",
    "    if count % 100 == 0:\n",
    "        print(str(count) + \" records have been processed\")\n",
    "        \n",
    "count = 0\n",
    "\n",
    "for i in train_y:\n",
    "    if i == \"unknown\":\n",
    "        count +=1\n",
    "\n",
    "uniqueLabels = []\n",
    "for i in train_y:\n",
    "    if i not in uniqueLabels:\n",
    "        uniqueLabels.append(i)\n",
    "        \n",
    "count = 0\n",
    "uniqueLabelMaps = []\n",
    "\n",
    "uniqueLabels.sort()\n",
    "for i in uniqueLabels:\n",
    "    uniqueLabelMaps.append([i, count])\n",
    "    count += 1\n",
    "    \n",
    "\n",
    "for i in range(len(train_y)):\n",
    "    for j in uniqueLabelMaps:\n",
    "        if train_y[i] == j[0]:\n",
    "            train_y[i] = j[1]\n",
    "            break\n",
    "            \n",
    "train_y = to_categorical(train_y)            \n",
    "            \n",
    "train_x = train_x /255\n",
    "os.chdir(\"C://Users//Kevin//Workspaces//Data//dogIdentification\")\n",
    "numpy.save(\"train_x\", train_x)\n",
    "numpy.save(\"train_y\", train_y)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 records have been processed\n",
      "200 records have been processed\n",
      "300 records have been processed\n",
      "400 records have been processed\n",
      "500 records have been processed\n",
      "600 records have been processed\n",
      "700 records have been processed\n",
      "800 records have been processed\n",
      "900 records have been processed\n",
      "1000 records have been processed\n",
      "1100 records have been processed\n",
      "1200 records have been processed\n",
      "1300 records have been processed\n",
      "1400 records have been processed\n",
      "1500 records have been processed\n",
      "1600 records have been processed\n",
      "1700 records have been processed\n",
      "1800 records have been processed\n",
      "1900 records have been processed\n",
      "2000 records have been processed\n",
      "2100 records have been processed\n",
      "2200 records have been processed\n",
      "2300 records have been processed\n",
      "2400 records have been processed\n",
      "2500 records have been processed\n",
      "2600 records have been processed\n",
      "2700 records have been processed\n",
      "2800 records have been processed\n",
      "2900 records have been processed\n",
      "3000 records have been processed\n",
      "3100 records have been processed\n",
      "3200 records have been processed\n",
      "3300 records have been processed\n",
      "3400 records have been processed\n",
      "3500 records have been processed\n",
      "3600 records have been processed\n",
      "3700 records have been processed\n",
      "3800 records have been processed\n",
      "3900 records have been processed\n",
      "4000 records have been processed\n",
      "4100 records have been processed\n",
      "4200 records have been processed\n",
      "4300 records have been processed\n",
      "4400 records have been processed\n",
      "4500 records have been processed\n",
      "4600 records have been processed\n",
      "4700 records have been processed\n",
      "4800 records have been processed\n",
      "4900 records have been processed\n",
      "5000 records have been processed\n",
      "5100 records have been processed\n",
      "5200 records have been processed\n",
      "5300 records have been processed\n",
      "5400 records have been processed\n",
      "5500 records have been processed\n",
      "5600 records have been processed\n",
      "5700 records have been processed\n",
      "5800 records have been processed\n",
      "5900 records have been processed\n",
      "6000 records have been processed\n",
      "6100 records have been processed\n",
      "6200 records have been processed\n",
      "6300 records have been processed\n",
      "6400 records have been processed\n",
      "6500 records have been processed\n",
      "6600 records have been processed\n",
      "6700 records have been processed\n",
      "6800 records have been processed\n",
      "6900 records have been processed\n",
      "7000 records have been processed\n",
      "7100 records have been processed\n",
      "7200 records have been processed\n",
      "7300 records have been processed\n",
      "7400 records have been processed\n",
      "7500 records have been processed\n",
      "7600 records have been processed\n",
      "7700 records have been processed\n",
      "7800 records have been processed\n",
      "7900 records have been processed\n",
      "8000 records have been processed\n",
      "8100 records have been processed\n",
      "8200 records have been processed\n",
      "8300 records have been processed\n",
      "8400 records have been processed\n",
      "8500 records have been processed\n",
      "8600 records have been processed\n",
      "8700 records have been processed\n",
      "8800 records have been processed\n",
      "8900 records have been processed\n",
      "9000 records have been processed\n",
      "9100 records have been processed\n",
      "9200 records have been processed\n",
      "9300 records have been processed\n",
      "9400 records have been processed\n",
      "9500 records have been processed\n",
      "9600 records have been processed\n",
      "9700 records have been processed\n",
      "9800 records have been processed\n",
      "9900 records have been processed\n",
      "10000 records have been processed\n",
      "10100 records have been processed\n",
      "10200 records have been processed\n",
      "10300 records have been processed\n",
      "1550.3598914146423\n"
     ]
    }
   ],
   "source": [
    "testLocation = \"C://Users//Kevin//Workspaces//Data//test\"\n",
    "os.chdir(testLocation)\n",
    "\n",
    "DESIRED_WIDTH = 128\n",
    "DESIRED_HEIGHT = 128\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "flag = 0\n",
    "count = 0\n",
    "test_y_column1 = []\n",
    "#Building test_x\n",
    "for file in glob.glob(\"*.jpg\"):\n",
    "    count += 1\n",
    "    \n",
    "    test_y_column1.append(file[:-4])\n",
    "    \n",
    "    original_image = PIL.Image.open(file)\n",
    "    transformed_image = original_image.resize( (DESIRED_HEIGHT, DESIRED_WIDTH) )\n",
    "    tempArray = numpy.array(transformed_image)\n",
    "    tempArray = numpy.expand_dims(tempArray, axis = 0)\n",
    "\n",
    "    if flag == 0:\n",
    "        test_x = tempArray\n",
    "        flag = 1\n",
    "    else:\n",
    "        test_x = numpy.append(test_x, tempArray, axis=0)\n",
    "    if count % 100 == 0:\n",
    "        print(str(count) + \" records have been processed\")\n",
    "\n",
    "test_x = test_x /255\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "numpy.save(\"test_x\", test_x)\n",
    "numpy.save(\"test_y_column1\", test_y_column1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsLocation = \"C://Users//Kevin//Workspaces//Data//dogIdentification//labels.csv\"\n",
    "labels=pd.read_csv(labelsLocation, sep=',')\n",
    "uniqueLabels = []\n",
    "for x in range(labels.shape[0]):\n",
    "    if labels.iloc[x,1] not in uniqueLabels:\n",
    "        uniqueLabels.append(labels.iloc[x,1])\n",
    "uniqueLabels.sort()\n",
    "\n",
    "def inception2B(x, nFilter = 32):\n",
    "    conv1 = Conv2D(nFilter, (1, 1), padding='same', activation='relu')(x)\n",
    "      \n",
    "    conv2 = Conv2D(nFilter, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv21 = Conv2D(nFilter, (3, 3), padding='same', activation='relu')(conv2)\n",
    "      \n",
    "    conv3 = Conv2D(nFilter, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv31 = Conv2D(nFilter, (5, 5), padding='same', activation='relu')(conv3)\n",
    "     \n",
    "    conv4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    conv41 = Conv2D(nFilter, (1,1), padding='same', activation='relu')(conv4)\n",
    "  \n",
    "    c2 = Concatenate(axis=-1)([conv1, conv21, conv31, conv41])\n",
    "    return c2\n",
    "\n",
    "def inception2BN(x, n = 32):\n",
    "    conv1 = Conv2D(n, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv1batchNorm=BatchNormalization()(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(n, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv2batchNorm=BatchNormalization()(conv2)\n",
    "  \n",
    "    conv21 = Conv2D(n, (3, 3), padding='same', activation='relu')(conv2batchNorm)\n",
    "      \n",
    "    conv3 = Conv2D(n, (1, 1), padding='same', activation='relu')(x)\n",
    "    conv3batchNorm=BatchNormalization()(conv3)\n",
    "    conv31 = Conv2D(n, (5, 5), padding='same', activation='relu')(conv3batchNorm)\n",
    "     \n",
    "    conv4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    conv41 = Conv2D(n, (1,1), padding='same', activation='relu')(conv4)\n",
    "  \n",
    "    c = Concatenate(axis=1)([conv1batchNorm, conv21, conv31, conv41])\n",
    "    return c\n",
    "\n",
    "def model2():\n",
    "    input=Input(shape=(DESIRED_HEIGHT, DESIRED_WIDTH, 3))\n",
    "    dropoutInput=Dropout(.4)(input)\n",
    "    inceptionFirst=inception2BN(dropoutInput)\n",
    "    maxPool1=MaxPooling2D((2,2),strides=(2,2),padding='same')(inceptionFirst)\n",
    "    inceptionSecond=inception2BN(maxPool1)\n",
    "    maxPool2=MaxPooling2D((2,2),strides=(2,2),padding='same')(inceptionSecond)    \n",
    "    flattenedLayer = Flatten()(maxPool2)\n",
    "    dropout = Dropout(.4)(flattenedLayer)\n",
    "    temp3=Dense(128,activation='relu')(dropout) \n",
    "    temp3BN = BatchNormalization()(temp3)\n",
    "    output_m1=Dense(len(uniqueLabels),activation='softmax')(temp3BN) \n",
    "    model=Model(input,output_m1) \n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 3)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 32) 128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 32) 9248        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 32) 25632       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 32) 128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 128, 32) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 256, 64, 32)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 64, 32)  1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 256, 64, 32)  1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 64, 32)  128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 64, 32)  128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 256, 64, 32)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 64, 32)  1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 64, 32)  9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 256, 64, 32)  25632       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 64, 32)  1056        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024, 64, 32) 0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 512, 32, 32)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 524288)       0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 524288)       0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           33554496    dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          7800        batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 33,637,560\n",
      "Trainable params: 33,637,176\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Train on 8177 samples, validate on 2045 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[5,32,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: concatenate_1/concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/concatenate_1/concat_grad/Slice_2\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, conv2d_3/Relu, conv2d_5/Relu, conv2d_6/Relu, concatenate_1/concat-4-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_547 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_973_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'concatenate_1/concat', defined at:\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-c4987844e531>\", line 10, in <module>\n    model=model2()\n  File \"<ipython-input-21-a6f9fe7d3a25>\", line 44, in model2\n    inceptionFirst=inception2BN(dropoutInput)\n  File \"<ipython-input-21-a6f9fe7d3a25>\", line 38, in inception2BN\n    c = Concatenate(axis=1)([conv1, conv21, conv31, conv41])\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\merge.py\", line 155, in call\n    return self._merge_function(inputs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\merge.py\", line 357, in _merge_function\n    return K.concatenate(inputs, axis=self.axis)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1885, in concatenate\n    return tf.concat([to_dense(x) for x in tensors], axis)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1189, in concat\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1105, in concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,32,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: concatenate_1/concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/concatenate_1/concat_grad/Slice_2\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, conv2d_3/Relu, conv2d_5/Relu, conv2d_6/Relu, concatenate_1/concat-4-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_547 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_973_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,32,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: concatenate_1/concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/concatenate_1/concat_grad/Slice_2\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, conv2d_3/Relu, conv2d_5/Relu, conv2d_6/Relu, concatenate_1/concat-4-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_547 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_973_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c4987844e531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[5,32,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: concatenate_1/concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/concatenate_1/concat_grad/Slice_2\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, conv2d_3/Relu, conv2d_5/Relu, conv2d_6/Relu, concatenate_1/concat-4-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_547 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_973_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'concatenate_1/concat', defined at:\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-c4987844e531>\", line 10, in <module>\n    model=model2()\n  File \"<ipython-input-21-a6f9fe7d3a25>\", line 44, in model2\n    inceptionFirst=inception2BN(dropoutInput)\n  File \"<ipython-input-21-a6f9fe7d3a25>\", line 38, in inception2BN\n    c = Concatenate(axis=1)([conv1, conv21, conv31, conv41])\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\merge.py\", line 155, in call\n    return self._merge_function(inputs)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\merge.py\", line 357, in _merge_function\n    return K.concatenate(inputs, axis=self.axis)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 1885, in concatenate\n    return tf.concat([to_dense(x) for x in tensors], axis)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1189, in concat\n    return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 1105, in concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"c:\\users\\kevin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[5,32,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: concatenate_1/concat = ConcatV2[N=4, T=DT_FLOAT, Tidx=DT_INT32, _class=[\"loc:@training/Adam/gradients/concatenate_1/concat_grad/Slice_2\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/Relu, conv2d_3/Relu, conv2d_5/Relu, conv2d_6/Relu, concatenate_1/concat-4-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dense_2/BiasAdd/_547 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_973_dense_2/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"C://Users//Kevin//Workspaces//Data//dogIdentification\")\n",
    "train_x = numpy.load(\"train_x.npy\")\n",
    "train_x = train_x.reshape(train_x.shape[0], DESIRED_HEIGHT, DESIRED_WIDTH, 3).astype( 'float32' )\n",
    "\n",
    "train_y = numpy.load(\"train_y.npy\")\n",
    "\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model=model2()\n",
    "highLearningAdam = Adam(lr=0.001)\n",
    "model.compile(optimizer=highLearningAdam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint('dogbreedIdentification.h5', monitor='val_loss', save_best_only=True)\n",
    "cb = [checkpoint]\n",
    "model.summary()  \n",
    "model.fit(train_x, train_y, validation_split=.2, callbacks=cb epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C://Users//Kevin//Workspaces//Data//test\")\n",
    "test_x = numpy.load(\"test_x.npy\")\n",
    "ycolumn1 = numpy.load(\"test_y_column1.npy\")\n",
    "\n",
    "K.clear_session()\n",
    "model=model2()\n",
    "highLearningAdam = Adam(lr=0.001)\n",
    "model.compile(optimizer=highLearningAdam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.load_weights('dogbreedIdentification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalOutput = []\n",
    "\n",
    "for i in range(test_x.shape[0]):\n",
    "    predictions = model.predict(test_x[i:i+1])\n",
    "    temp = [ycolumn1[i]]\n",
    "    for prediction in predictions:\n",
    "        for number in prediction:\n",
    "            temp.append(number)\n",
    "    finalOutput.append(temp)\n",
    "\n",
    "tempList = [\"id\"]\n",
    "for name in uniqueLabels:\n",
    "    tempList.append(name)\n",
    "\n",
    "\n",
    "submissionListOfLists = [tempList]\n",
    "for row in finalOutput:\n",
    "    submissionListOfLists.append(row)\n",
    "finalOutput = pd.DataFrame(numpy.array(submissionListOfLists))\n",
    "finalOutput.to_csv(\"submission.csv\", header = False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The last bit of codes creates the submission file in the proper format with the proper row ids and column names, yielding a\n",
    "prediction column space for each id.\n",
    "\n",
    "Looking over the poor performance of the model generalizing, and looking through the data, I can think of a few things that\n",
    "are absolutely critical to making the model more effective. These include the following:\n",
    "\n",
    "1) Using a bigger image size, preferably 256x256\n",
    "    - this is limited by computing power and the resource. Using a 1.4 gb gpu was not sufficient for this project, requiring\n",
    "        a migration to colab\n",
    "    - this is expected to capture more defining curves of the dogs\n",
    "2) Background blackout, due to confounding image colours\n",
    "    - this is beyond my personal scope of ability. It first requires classifying the image in the background as the target\n",
    "        using image recognition, then zeroing out all other pixels\n",
    "    - I expect this to be the most important thing for this image, as in identifying dogs we need to use the full RGB spectrum,\n",
    "        and looking at the images, our feature space for 123 target variables is severely hampered by the diversity of color \n",
    "        backgrounds.\n",
    "3) More data\n",
    "    - an obvious solution is image augmentation, but in this case, with 123 target variables 10,000 samples might not be truly\n",
    "        enough, especially given the diversity of environments the photos were taken in. This can be circumvented using \n",
    "        solution #2, as I believe that to be the most important thing\n",
    "4) Better model.\n",
    "    - Without 1, 2, or 3, this will not alone give the best performance, but finer tuning can be performed once a cross validation\n",
    "        goes above .1, which I managed to get on a single test.\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
